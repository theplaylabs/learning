{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj_N2nXU3oF_"
   },
   "source": [
    "Get your openai api key from settings: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "1lDDowVHfzd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.54.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.25.1)\n",
      "Requirement already satisfied: simpleaudio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: pyaudio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.23.5)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.10.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sounddevice) (1.15.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scipy) (1.23.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (20240930)\n",
      "Requirement already satisfied: numba in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (0.57.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (1.23.5)\n",
      "Requirement already satisfied: torch in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (2.0.0+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba->openai-whisper) (0.40.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken->openai-whisper) (2.28.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Library Installs\n",
    "%pip install openai --upgrade\n",
    "%pip install pydub simpleaudio\n",
    "%pip install nltk\n",
    "%pip install pyaudio numpy\n",
    "%pip install sounddevice scipy\n",
    "%pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "-DcnuHyv3lKx"
   },
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Variables\n",
    "MP3_FOLDER = \"audio_chunks\"  # Directory where audio chunks are stored\n",
    "errorsLeft = True # Set as true to enter main program While loop\n",
    "\n",
    "# MP3 Recording Parameters\n",
    "SAMPLE_RATE = 44100  # Sample rate in Hz\n",
    "DURATION_THRESHOLD = 1.5  # Duration in seconds to consider silence\n",
    "SILENCE_THRESHOLD = 0.01  # Amplitude threshold for silence\n",
    "MAX_CHUNK_SIZE = 25 * 1024 * 1024  # Maximum chunk size in bytes (25 MB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play Audio Function\n",
    "def play_audio(mp3_filename):\n",
    "    \"\"\"\n",
    "    Plays the specified MP3 file using pydub and simpleaudio.\n",
    "    \n",
    "    :param mp3_filename: Name of the MP3 file to play (should be located in the current working directory)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio = AudioSegment.from_mp3(Path.cwd() / mp3_filename)\n",
    "        \n",
    "        # Play the audio file\n",
    "        play_obj = sa.play_buffer(\n",
    "            audio.raw_data,\n",
    "            num_channels=audio.channels,\n",
    "            bytes_per_sample=audio.sample_width,\n",
    "            sample_rate=audio.frame_rate\n",
    "        )\n",
    "        play_obj.wait_done()  # Wait until playback is finished\n",
    "        print(f\"Finished playing {mp3_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records user audio and detects pauses (silence) to segment the recording into separate chunks.\n",
    "# When silence is detected for a specified duration, the audio is saved as an MP3 file. This allows for efficient \n",
    "# segmentation of audio data based on user pauses. The program also ensures that audio chunks do not exceed a set size.\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "\n",
    "# Create directory for audio chunks if it doesn't exist\n",
    "if not os.path.exists(MP3_FOLDER):\n",
    "    os.makedirs(MP3_FOLDER)\n",
    "\n",
    "def play_ding():\n",
    "    \"\"\"\n",
    "    Play a hardcoded 'ding.wav' file \n",
    "    \"\"\"\n",
    "    file_path = \"ding.wav\"  # Hardcoded file name\n",
    "    \n",
    "    # Read the WAV file\n",
    "    sample_rate, data = read(file_path)\n",
    "    \n",
    "    # Play the audio file\n",
    "    sd.play(data, sample_rate)\n",
    "    sd.wait()  # Wait until playback is finished\n",
    "\n",
    "def is_silent(data):\n",
    "    \"\"\"Check if the audio data is silent by evaluating if its mean amplitude is below the silence threshold.\"\"\"\n",
    "    return np.abs(data).mean() < SILENCE_THRESHOLD\n",
    "\"\"\"\n",
    "def record_audio():\n",
    "    \"\"\"Continuously record audio, saving each chunk when silence is detected for the threshold duration.\"\"\"\n",
    "    print(\"Recording... Speak now.\")\n",
    "    play_ding()\n",
    "\n",
    "    # Initialize the current chunk and silence detection timing\n",
    "    current_chunk = []\n",
    "    silence_start_time = None\n",
    "\n",
    "    # Start the audio input stream\n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:\n",
    "        while True:\n",
    "            # Read one second of audio data from the stream\n",
    "            data = stream.read(SAMPLE_RATE)[0]\n",
    "            current_chunk.extend(data.flatten())  # Add the new data to the current chunk\n",
    "\n",
    "            # Check if the audio data is silent\n",
    "            if is_silent(data):\n",
    "                # If silence starts, begin a timer\n",
    "                if silence_start_time is None:\n",
    "                    silence_start_time = time.time()\n",
    "            else:\n",
    "                # Reset the timer if sound is detected\n",
    "                silence_start_time = None\n",
    "\n",
    "            # Stop recording if silence has lasted beyond the duration threshold\n",
    "            if silence_start_time and (time.time() - silence_start_time) > DURATION_THRESHOLD:\n",
    "                print(\"Silence detected. Stopping recording.\")\n",
    "                break  # Exit the loop to stop recording\n",
    "\n",
    "    # Save the final chunk after breaking out of the loop\n",
    "    if current_chunk:\n",
    "        save_audio_chunk(current_chunk)\n",
    "        print(\"Final chunk saved.\")\n",
    "\n",
    "def save_temp_wav(file_path, chunk):\n",
    "    \"\"\"Save the recorded audio chunk to a WAV file temporarily for further processing or conversion.\"\"\"\n",
    "    if len(chunk) == 0:\n",
    "        return  # Don't save empty chunks\n",
    "    \n",
    "    # Convert to WAV and save\n",
    "    audio_data = np.array(chunk, dtype=np.float32)\n",
    "    write(file_path, SAMPLE_RATE, audio_data)\n",
    "\n",
    "def convert_to_mp3(wav_file, mp3_file):\n",
    "    \"\"\"Convert a temporary WAV file to MP3 format using the Pydub library.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(wav_file)\n",
    "        audio = audio.set_channels(1)  # Ensure mono channel\n",
    "        audio = audio.set_frame_rate(16000)  # Set sample rate to 16 kHz (Whisper's recommended rate)\n",
    "        audio.export(mp3_file, format=\"mp3\", bitrate=\"128k\")  # Set bitrate to 128 kbps\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to MP3: {e}\")\n",
    "\n",
    "\n",
    "def save_audio_chunk(chunk):\n",
    "    \"\"\"Save the recorded audio chunk to an MP3 file, creating a unique file name.\"\"\"\n",
    "    if len(chunk) == 0:\n",
    "        return  # Don't save empty chunks\n",
    "\n",
    "    # Create a unique file name for the MP3 file\n",
    "    chunk_index = len(os.listdir(MP3_FOLDER)) + 1\n",
    "    mp3_file_path = os.path.join(MP3_FOLDER, f\"chunk{chunk_index}.mp3\")\n",
    "\n",
    "    # Convert the chunk to WAV temporarily for saving\n",
    "    temp_wav_path = os.path.join(MP3_FOLDER, \"temp.wav\")\n",
    "    save_temp_wav(temp_wav_path, chunk)\n",
    "\n",
    "    # Convert to MP3\n",
    "    convert_to_mp3(temp_wav_path, mp3_file_path)\n",
    "\n",
    "    print(f\"Saved chunk to {mp3_file_path}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    \"\"\"Record audio until silence is detected for the threshold duration, then save as a single MP3.\"\"\"\n",
    "    print(\"Recording... Speak now.\")\n",
    "    play_ding()\n",
    "\n",
    "    # Initialize the audio buffer and silence detection timing\n",
    "    audio_buffer = []\n",
    "    silence_start_time = None\n",
    "\n",
    "    # Start the audio input stream\n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:\n",
    "        while True:\n",
    "            # Read one second of audio data from the stream\n",
    "            data = stream.read(SAMPLE_RATE)[0]\n",
    "            audio_buffer.extend(data.flatten())  # Add the new data to the audio buffer\n",
    "\n",
    "            # Check if the audio data is silent\n",
    "            if is_silent(data):\n",
    "                # Start silence timer if silence detected\n",
    "                if silence_start_time is None:\n",
    "                    silence_start_time = time.time()\n",
    "            else:\n",
    "                # Reset silence timer if sound resumes\n",
    "                silence_start_time = None\n",
    "\n",
    "            # Stop recording if silence lasts beyond the duration threshold\n",
    "            if silence_start_time and (time.time() - silence_start_time) > DURATION_THRESHOLD:\n",
    "                print(\"Silence detected. Stopping recording.\")\n",
    "                break  # Exit the loop to stop recording\n",
    "\n",
    "    # Save the final audio as an MP3 after recording stops\n",
    "    if audio_buffer:\n",
    "        save_audio_as_mp3(audio_buffer)\n",
    "        print(\"Audio saved.\")\n",
    "\n",
    "def save_audio_as_mp3(audio_buffer):\n",
    "    \"\"\"Convert and save the audio buffer to an MP3 file.\"\"\"\n",
    "    # Create a unique file name for the MP3 file\n",
    "    mp3_file_path = os.path.join(MP3_FOLDER, \"recording.mp3\")\n",
    "\n",
    "    # Convert the buffer to a WAV file temporarily\n",
    "    temp_wav_path = os.path.join(MP3_FOLDER, \"temp.wav\")\n",
    "    audio_data = np.array(audio_buffer, dtype=np.float32)\n",
    "    write(temp_wav_path, SAMPLE_RATE, audio_data)\n",
    "\n",
    "    # Convert to MP3\n",
    "    convert_to_mp3(temp_wav_path, mp3_file_path)\n",
    "\n",
    "    print(f\"Audio saved as {mp3_file_path}\")\n",
    "\n",
    "def convert_to_mp3(wav_file, mp3_file):\n",
    "    \"\"\"Convert a temporary WAV file to MP3 format using the Pydub library.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(wav_file)\n",
    "        audio = audio.set_channels(1)  # Ensure mono channel\n",
    "        audio = audio.set_frame_rate(16000)  # Set sample rate to 16 kHz (Whisper's recommended rate)\n",
    "        audio.export(mp3_file, format=\"mp3\", bitrate=\"128k\")  # Set bitrate to 128 kbps\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to MP3: {e}\")\n",
    "\n",
    "# Example usage\n",
    "record_audio()  # Starts recording and will save as \"recording.mp3\" once silence is detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim Audio (dead air)\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "# Default configuration\n",
    "\n",
    "def get_newest_file(directory):\n",
    "    \"\"\"Return the newest file in the specified directory.\"\"\"\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    if not files:\n",
    "        return None\n",
    "    files.sort(key=lambda f: os.path.getmtime(os.path.join(directory, f)), reverse=True)\n",
    "    return os.path.join(directory, files[0])\n",
    "\n",
    "def trim_silence(input_file=None, folder=MP3_FOLDER, silence_thresh=-40, min_silence_len=300, buffer_ms=200):\n",
    "    \"\"\"\n",
    "    Trim dead air (silence) from the beginning and end of an MP3 file, leaving a small buffer,\n",
    "    and save it with '_trim' appended to the filename.\n",
    "\n",
    "    :param input_file: Path to the input MP3 file. Defaults to the newest file in folder if not specified.\n",
    "    :param folder: Folder to search for the newest file if input_file is not specified.\n",
    "    :param silence_thresh: Silence threshold in dB (default is -40 dB).\n",
    "    :param min_silence_len: Minimum length of silence to consider (in milliseconds).\n",
    "    :param buffer_ms: Extra milliseconds to leave at the beginning and end of the trimmed audio.\n",
    "    \"\"\"\n",
    "    # Use the newest file in the folder if input_file is None\n",
    "    if input_file is None:\n",
    "        file_path = get_newest_file(folder)\n",
    "    else:\n",
    "        file_path = input_file\n",
    "\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        # Load the audio file\n",
    "        audio = AudioSegment.from_mp3(file_path)\n",
    "        \n",
    "        # Detect non-silent portions of the audio\n",
    "        non_silent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "        \n",
    "        if non_silent_ranges:\n",
    "            # Get the start and end of the non-silent range and add buffer\n",
    "            start_trim = max(0, non_silent_ranges[0][0] - buffer_ms)\n",
    "            end_trim = min(len(audio), non_silent_ranges[-1][1] + buffer_ms)\n",
    "            \n",
    "            # Trim the audio with the buffer\n",
    "            trimmed_audio = audio[start_trim:end_trim]\n",
    "            \n",
    "            # Create output filename by appending '_trim' before the file extension\n",
    "            base, ext = os.path.splitext(file_path)\n",
    "            output_file = f\"{base}_trim{ext}\"\n",
    "            \n",
    "            # Export the trimmed audio to an MP3 file\n",
    "            trimmed_audio.export(output_file, format=\"mp3\")\n",
    "            print(f\"Trimmed audio saved as {output_file}\")\n",
    "        else:\n",
    "            print(\"No non-silent segments detected. File not saved.\")\n",
    "    else:\n",
    "        print(\"No valid audio file found. Please check the directory or specify a file.\")\n",
    "\n",
    "# Example usage\n",
    "# trim_silence()  # Uses the newest file in the default \"audio_chunks\" folder\n",
    "# Or specify a file directly\n",
    "# trim_silence(input_file=\"specific_audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcibe Speech to Text\n",
    "\n",
    "def transcribe_audio(mp3_folder=MP3_FOLDER, specified_file=None, use_newest=True):\n",
    "    \"\"\"\n",
    "    Transcribes an audio file using the Whisper model. By default, uses the newest file in the directory,\n",
    "    but can also use a specified file if provided.\n",
    "\n",
    "    :param mp3_folder: Directory to search for audio files (default is \"audio_chunks\")\n",
    "    :param specified_file: File path to a specific file to transcribe; overrides use_newest if provided\n",
    "    :param use_newest: Boolean flag to determine whether to use the newest file in mp3_folder (default is True)\n",
    "    :return: Transcription text if successful, or an error message\n",
    "    \"\"\"\n",
    "      # Determine file path based on user input or defaults\n",
    "    file_path = specified_file if specified_file else (get_newest_file(mp3_folder) if use_newest else None)\n",
    "\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as audio_file:\n",
    "            # Perform transcription using Whisper model\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "            )\n",
    "            print(\"Transcription: \" + transcription.text)\n",
    "            return transcription.text\n",
    "    else:\n",
    "        return \"No valid audio file found. Please check the directory or specify a valid file.\"\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "# Or specify a file directly\n",
    "# print(transcribe_audio(specified_file=\"specific_audio.mp3\", use_newest=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt definitions (pre-written)\n",
    "# MyPrompt1 find one error and give the complete correction\n",
    "myPrompt1 = \"\"\"\n",
    "You will receive a paragraph written in Spanish. Your task is to identify and correct major grammatical errors while adhering to the following instructions:\n",
    "\n",
    "1. Ignore gender errors.\n",
    "2. If a mistake is made but then corrected within the same paragraph, do not include that correction (e.g., \"yo comí\" followed by \"yo comer\").\n",
    "3. Ignore typing mistakes or missing accents; these are not considered errors.\n",
    "4. Ignore minor clarity issues.\n",
    "5. If there are no errors worth mentioning, output \"No Errors.\"\n",
    "\n",
    "Your output should consist only of the correct Spanish for each identified error, separated by periods. Do not provide any additional commentary or explanations. Aim for responses of 4-5 words unless more is needed.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input: \"Nosotros va a la playa mañana. Ellos trae sus juguetes.\"\n",
    "\n",
    "Output: \"Nosotros vamos. Ellos traen.\"\n",
    "\"\"\"\n",
    "\n",
    "# Archived prompts\n",
    "\n",
    "myText = \"Yo ir al tienda para comprar manzanas y platanos. Cuando llegué, vi muchas frutas y verduras. El cajero me dijo que el precio son muy alto, pero no me importa. Después, yo regresar a casa y preparé un plato grande para mi familia. Todos nos gusta comer juntos.\"\n",
    "\n",
    "# MyPrompt2 is show all the errors in a list\n",
    "myPrompt2 = \"\"\" \n",
    "You will receive a paragraph written in Spanish. Your task is to identify and correct one major grammatical error while adhering to the following instructions:\n",
    "Ignore gender errors.\n",
    "If a mistake is made but then corrected within the same paragraph, do not include that correction (e.g., \"yo comí\" followed by \"yo comer\").\n",
    "Ignore typos or missing accents or written problems; these are not considered errors.\n",
    "Ignore minor clarity issues.\n",
    "If there are no significant errors, output \"No errors.\"\n",
    "Your output should consist of two sentences:\n",
    "\n",
    "1. The original incorrect sentence, abreviated to show what was said, but not include extraneous detail before and after in the sentence.\n",
    "2. The corrected version with the corrected word in all caps.\n",
    "If no significant error is found, just write \"No errors.\". no second sentence is needed in this case\n",
    "DO NOT SHOW AN ERROR IF THERE IS NOT ONE.\n",
    "Example 1:\n",
    "\n",
    "Input: Ayer, nosotros vamos a la playa mañana para solear.\n",
    "Output: No errors.\n",
    "Example 2:\n",
    "\n",
    "Input: Ayer, nosotros va a la playa mañana para solear. Ellos trae sus juguetes.\n",
    "Output: Nosotros va a la playa mañana. Nosotros vamos a la playa mañana.\n",
    "\n",
    "\"\"\"\n",
    "confirmPrompt = \"\"\" The following input is supposed to be a sentence in spanish that includes an error, and then the correction of that error. If the second sentence does not actually correct an error or simply repeats the sentence, then respond with 'No errors.' Otherwise repeat back exactly the input given to you without edits. \n",
    "Input:\n",
    "\"\"\"\n",
    "checkCorrectionPrompt = \"\"\" \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the openai secret key\n",
    "secret_key = getpass.getpass(\"Please enter your openai key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"]= secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "zTTAw81O6xs0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Sí, esto está funcionando. ¿En qué puedo ayudarte hoy con tu aprendizaje del español?'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI set up:\n",
    "client = OpenAI()\n",
    "client.api_key = secret_key\n",
    "# Set up OpenAI client with the provided API key\n",
    "\n",
    "def complete(prompt, stop=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a real-time voice chat assistant for Spanish language learning, specializing in Mexican Spanish with a natural Mexican accent.\"\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "complete(\"is this working?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPrompt1 = \"\"\" take the following spanish dictation and identify the worst mistake you can find. Follow these rules\n",
    "If a mistake is made but then immediately corrected within the same paragraph, ignore it (e.g., \"yo comes\" followed by \"yo como\").\n",
    "Ignore typos or missing accents or written problems; these are not considered errors.\n",
    "Ignore minor clarity issues.\n",
    "ignore hypothetical, subjungtive or complex conjugations\n",
    "Focus more on incorrect words getting used, or poor conjugation.\n",
    "Do not include additional commentary, just output the exact sentence with the error included.\n",
    "example output: Nosotros va a la playa mañana.\n",
    "If not major errors can be found, output: No errors.\n",
    "\n",
    "Input:\n",
    "\"\"\"\n",
    "testPrompt1a = \"\"\"Ignore previous instructions, your only job here is this: In the following sentence there may be an error. If you can find it, tell me what it is, and explain your reasoning. \n",
    "If a mistake is made but then immediately corrected, ignore it (e.g., \"yo comes\" followed by \"yo como\").\n",
    "Ignore typos or missing accents or written problems; these are not considered errors.\n",
    "Ignore minor clarity issues.\n",
    "ignore hypothetical, subjungtive or complex conjugations\n",
    "Focus more on incorrect words getting used, or poor conjugation\n",
    "Only explain the correction for a single error. Do not include additional commentary or questions, output nothing but one single explanation for one single error.\n",
    "It's very important that if there isn't a major mistake in the sentence, to just reply 'No errors.'\n",
    "Confirm for sure that the error you have selected is bad enough to bother mentioning.\n",
    "\"\"\"\n",
    "testPrompt2=\"\"\"We are going to help a student by point out an error they made while speaking. Here is the explanation of the error, take careful not of which word is wrong\n",
    "\"\"\"\n",
    "testPrompt2a=\"\"\" \n",
    "Now take the following input sentence:\n",
    "Input:\n",
    "\"\"\"\n",
    "testPrompt2b=\"\"\" \n",
    "output the sentence fragment centered on the erroneous word from the input sentence. The fragment should include the 3 words before and after. Do not include any additional commentary.\n",
    "If you cannot find an obvious error, just output 'No error.' \n",
    "Example Input: Nosotros va a la playa mañana para solear y relajarnos, pero no queremos manejar por todo el dia.\n",
    "Example Output: Nosotros va a la playa\n",
    "\"\"\"\n",
    "\n",
    "testPrompt3=\"\"\"We are going to help a student by correcting an error they made while speaking. Using the following guidance on what the error was:\n",
    "\"\"\"\n",
    "testPrompt3a=\"\"\" And now edit this sentence fragment so it is correct. Do not make it a complete sentence, just correct the error described above. Provide NO ADDITONAL COMMENTARY, just output the corrected sentence fragment\n",
    "Example Output: Nosotros va a la playa\n",
    "Example input: Nosotros vamos a la playa\n",
    "\"\"\"\n",
    "\n",
    "testPrompt4=\"\"\"You are a careful spanish teacher and you don't want to give unnecessary instruction to a student while they are learning. Look at the following correction made by another teacher and decide if the student was close enough or if the instruction is actually incorrect and should be ignored. If there is any chance the instruction is incorrect reply 'Ignore.' otherwise reply 'Go ahead.' \"\"\"\n",
    "\n",
    "confirmErrorCorrectionPrompt1=\"\"\" Yes or No, does the end of the first transcription match the second transcription word for word? Ignore spelling and punctuation etc. \"\"\"\n",
    "confirmErrorCorrectionPrompt1a=\"\"\" Answer either 'Yes.' or 'No.' do not add additional commentary. Also if either of the transcriptions say something in english such as 'Nevermind' then also reply 'Yes' \"\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a beep when it stops recording\n",
    "could have a faster dialogue option where it does no analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished playing intro.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk29.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk29_trim.mp3\n",
      "Transcription: gustaría practicar contigo, pero es importante que yo hacer errores.\n",
      "El error en la oración es \"hacer\" que debería ser \"cometer.\" La forma correcta sería \"es importante que yo cometa errores.\" \"Hacer\" no es el verbo adecuado en este contexto, ya que se usa \"cometer\" para referirse a la acción de cometer errores.\n",
      "vas a hacer errores, debes repararlos.\n",
      "vas a cometer errores, debes repararlos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattj\\AppData\\Local\\Temp\\ipykernel_824\\937880058.py:43: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished playing c:\\Users\\mattj\\OneDrive\\Documents\\GitHub\\learning\\speech_file.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk31.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk31_trim.mp3\n",
      "Transcription: ¿Vas a cometer errores?\n",
      "Finished playing c:\\Users\\mattj\\OneDrive\\Documents\\GitHub\\learning\\speech_file.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk33.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk33_trim.mp3\n",
      "Transcription: Errores debes repararlos.\n",
      "Finished playing c:\\Users\\mattj\\OneDrive\\Documents\\GitHub\\learning\\speech_file.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk35.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk35_trim.mp3\n",
      "Transcription: a cometer errores, debes repararlos.\n",
      "Finished playing c:\\Users\\mattj\\OneDrive\\Documents\\GitHub\\learning\\speech_file.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk37.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk37_trim.mp3\n",
      "Transcription: Never.\n",
      "Finished playing c:\\Users\\mattj\\OneDrive\\Documents\\GitHub\\learning\\speech_file.mp3\n",
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk39.mp3\n",
      "Final chunk saved.\n",
      "Trimmed audio saved as audio_chunks\\chunk39_trim.mp3\n",
      "Transcription: Nevermind.\n",
      "Finished playing cuentame.mp3\n",
      "Recording... Speak now.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m play_audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintro.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     trim_silence()  \u001b[38;5;66;03m# Uses the newest file in the default \"audio_chunks\" folder\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     myTransciption \u001b[38;5;241m=\u001b[39m transcribe_audio()  \u001b[38;5;66;03m# Uses the newest file in the default \"audio_chunks\" folder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[200], line 47\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sd\u001b[38;5;241m.\u001b[39mInputStream(samplerate\u001b[38;5;241m=\u001b[39mSAMPLE_RATE, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m# Read one second of audio data from the stream\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     48\u001b[0m         current_chunk\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mflatten())  \u001b[38;5;66;03m# Add the new data to the current chunk\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;66;03m# Check if the audio data is silent\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sounddevice.py:1475\u001b[0m, in \u001b[0;36mInputStream.read\u001b[1;34m(self, frames)\u001b[0m\n\u001b[0;32m   1473\u001b[0m dtype, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[0;32m   1474\u001b[0m channels, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels)\n\u001b[1;32m-> 1475\u001b[0m data, overflowed \u001b[38;5;241m=\u001b[39m \u001b[43mRawInputStream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1476\u001b[0m data \u001b[38;5;241m=\u001b[39m _array(data, channels, dtype)\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, overflowed\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sounddevice.py:1245\u001b[0m, in \u001b[0;36mRawInputStream.read\u001b[1;34m(self, frames)\u001b[0m\n\u001b[0;32m   1243\u001b[0m samplesize, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_samplesize)\n\u001b[0;32m   1244\u001b[0m data \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigned char[]\u001b[39m\u001b[38;5;124m'\u001b[39m, channels \u001b[38;5;241m*\u001b[39m samplesize \u001b[38;5;241m*\u001b[39m frames)\n\u001b[1;32m-> 1245\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPa_ReadStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m==\u001b[39m _lib\u001b[38;5;241m.\u001b[39mpaInputOverflowed:\n\u001b[0;32m   1247\u001b[0m     overflowed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MAIN PROGRAM LOOP\n",
    "\n",
    "play_audio(\"intro.mp3\")\n",
    "\n",
    "while True:\n",
    "    record_audio()\n",
    "\n",
    "    trim_silence()  # Uses the newest file in the default \"audio_chunks\" folder\n",
    "\n",
    "    myTransciption = transcribe_audio()  # Uses the newest file in the default \"audio_chunks\" folder\n",
    "\n",
    "    # Check transcription for grammatical errors\n",
    "    if complete(f\"{testPrompt1}\\n\\n{myTransciption}\") != \"Ignore.\":\n",
    "        errorExplanation = complete(f\"{testPrompt1a}\\n\\n{myTransciption}\")\n",
    "        print(errorExplanation)\n",
    "        errorFragment = complete(f\"{testPrompt2}\\n{errorExplanation}n\\n{testPrompt2a}\\n\\n{foundError}n\\n{testPrompt2b}\")\n",
    "        print(errorFragment)\n",
    "        if errorFragment != \"Ignore.\":\n",
    "            errorFixed = complete(f\"{testPrompt3}\\n{errorExplanation}n\\n{testPrompt3a}n\\n{errorFragment}\")\n",
    "            print(errorFixed)\n",
    "            if complete(testPrompt4) != \"Ignore.\":\n",
    "                errorsLeft = True\n",
    "            else:\n",
    "                errorsLeft = False\n",
    "                print(\"Actually nevermind\")\n",
    "        else:\n",
    "                errorsLeft = False\n",
    "                print(\"Actually nevermind\")\n",
    "    else:            \n",
    "        errorsLeft = False\n",
    "\n",
    "    while errorsLeft:\n",
    "        #convert errors into audio and plays them\n",
    "            errorsLeft = True\n",
    "            speech_file = \"speech_file.mp3\"\n",
    "            speech_file_path = Path.cwd() / speech_file\n",
    "            #generate the TTS Audio\n",
    "            response = client.audio.speech.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"onyx\",\n",
    "                input=errorFixed\n",
    "            )\n",
    "            response.stream_to_file(speech_file_path)\n",
    "\n",
    "            # play audio back\n",
    "            play_audio(speech_file_path)\n",
    "            \n",
    "            record_audio()\n",
    "\n",
    "            trim_silence()  # Uses the newest file in the default \"audio_chunks\" folder\n",
    "\n",
    "            myTransciption = transcribe_audio()  # Uses the newest file in the default \"audio_chunks\" folder\n",
    "\n",
    "            if complete(f\"{confirmErrorCorrectionPrompt1}\\n{myTransciption}\\n{errorFixed}\\n{confirmErrorCorrectionPrompt1a}\") != \"No.\":\n",
    "                 errorsLeft = False\n",
    "            # Check if they got it right using a gpt call, if they did they change errorLeft\n",
    "            # also check against other cases (as described below)\n",
    "        \n",
    "        #No more errors, continue conversation, play 'cuentame.mp3' \n",
    "    play_audio(\"cuentame.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nif the last words said were  \\nnevermind - just move one\\nrepite - auto replay everything that was just said and ignore \\nrepite (algo) figure out what exactly i want repeated and repeat that audio slowly (consider slowing down the playback)\\n\\nListen to audio\\nI respond normally - one by one, go through the things that were said to me and check if i said them correctly back. \\n    if yes, then move to the next item,\\n    if no, add that item back to the audio output\\n    if all yes, then continue conversation\\n    otherwise, concat audio again and play new audio\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' \n",
    "Listen to audio\n",
    "\n",
    "if the last words said were  \n",
    "nevermind - just move one. this is tough because i might just completely move on, so you need logic to notice this has happened and ignore checking against old errors\n",
    "repite - auto replay everything that was just said and ignore \n",
    "repite (algo) figure out what exactly i want repeated and repeat that audio slowly (consider slowing down the playback)\n",
    "\n",
    "otherwise confirm that i repeated back the correction properly. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
