{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj_N2nXU3oF_"
   },
   "source": [
    "Get your openai api key from settings: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1lDDowVHfzd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.54.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.54.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Downloading openai-1.54.2-py3-none-any.whl (389 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.1\n",
      "    Uninstalling openai-1.54.1:\n",
      "      Successfully uninstalled openai-1.54.1\n",
      "Successfully installed openai-1.54.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.25.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: simpleaudio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.10.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sounddevice) (1.15.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scipy) (1.23.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "     ---------------------------------------- 0.0/800.5 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/800.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 800.5/800.5 kB 2.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (0.57.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (1.23.5)\n",
      "Requirement already satisfied: torch in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (2.0.0+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-whisper) (4.65.0)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba->openai-whisper) (0.40.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken->openai-whisper) (2.28.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mattj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.5/884.5 kB 3.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803358 sha256=1933ef943b3b61efce9b28f5aab3f41399e4e3f3a99f2bb8a48982a56d402746\n",
      "  Stored in directory: c:\\users\\mattj\\appdata\\local\\pip\\cache\\wheels\\2f\\f2\\ce\\6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, tiktoken, openai-whisper\n",
      "Successfully installed more-itertools-10.5.0 openai-whisper-20240930 tiktoken-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mattj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --upgrade\n",
    "%pip install pydub simpleaudio\n",
    "%pip install nltk\n",
    "%pip install pyaudio numpy\n",
    "%pip install sounddevice scipy\n",
    "%pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-DcnuHyv3lKx"
   },
   "outputs": [],
   "source": [
    "# Get the openai secret key\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "secret_key = getpass.getpass(\"Please enter your openai key: \")\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]= secret_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zTTAw81O6xs0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Sí, aquí estoy. ¿Cómo te puedo ayudar con tu aprendizaje del español?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# OpenAI set up:\n",
    "client = OpenAI()\n",
    "client.api_key = secret_key\n",
    "# Set up OpenAI client with the provided API key\n",
    "\n",
    "def complete(prompt, stop=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a real-time voice chat assistant for Spanish language learning, specializing in Mexican Spanish with a natural Mexican accent.\"\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "complete(\"is this working?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattj\\AppData\\Local\\Temp\\ipykernel_3080\\3526707331.py:13: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "#client = OpenAI()\n",
    "filename1 = \"speech.mp3\"\n",
    "\n",
    "speech_file_path = Path.cwd() / filename1\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"onyx\",\n",
    "  input=\"a tu orden\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Play the intro.mp3 to begin things\n",
    "filename1 = \"intro.mp3\"\n",
    "\n",
    "#speech_file_path = Path(\"speech.mp3\")\n",
    "# Load and play the audio file\n",
    "speech_file_path = Path.cwd() / filename1\n",
    "audio = AudioSegment.from_mp3(speech_file_path)\n",
    "play_obj = sa.play_buffer(\n",
    "    audio.raw_data,\n",
    "    num_channels=audio.channels,\n",
    "    bytes_per_sample=audio.sample_width,\n",
    "    sample_rate=audio.frame_rate\n",
    ")\n",
    "play_obj.wait_done()  # Wait until playback is finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak now.\n",
      "Silence detected. Stopping recording.\n",
      "Saved chunk to audio_chunks\\chunk9.mp3\n",
      "Final chunk saved.\n"
     ]
    }
   ],
   "source": [
    "# Records user audio and detects pauses (silence) to segment the recording into separate chunks.\n",
    "# When silence is detected for a specified duration, the audio is saved as an MP3 file. This allows for efficient \n",
    "# segmentation of audio data based on user pauses. The program also ensures that audio chunks do not exceed a set size.\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Parameters\n",
    "SAMPLE_RATE = 44100  # Sample rate in Hz\n",
    "DURATION_THRESHOLD = 1.5  # Duration in seconds to consider silence\n",
    "SILENCE_THRESHOLD = 0.01  # Amplitude threshold for silence\n",
    "MAX_CHUNK_SIZE = 25 * 1024 * 1024  # Maximum chunk size in bytes (25 MB)\n",
    "CHUNK_FOLDER = \"audio_chunks\"  # Folder to save audio chunks\n",
    "\n",
    "# Create directory for audio chunks if it doesn't exist\n",
    "if not os.path.exists(CHUNK_FOLDER):\n",
    "    os.makedirs(CHUNK_FOLDER)\n",
    "\n",
    "def is_silent(data):\n",
    "    \"\"\"Check if the audio data is silent by evaluating if its mean amplitude is below the silence threshold.\"\"\"\n",
    "    return np.abs(data).mean() < SILENCE_THRESHOLD\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"Continuously record audio, saving each chunk when silence is detected for the threshold duration.\"\"\"\n",
    "    print(\"Recording... Speak now.\")\n",
    "\n",
    "    # Initialize the current chunk and silence detection timing\n",
    "    current_chunk = []\n",
    "    silence_start_time = None\n",
    "\n",
    "    # Start the audio input stream\n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:\n",
    "        while True:\n",
    "            # Read one second of audio data from the stream\n",
    "            data = stream.read(SAMPLE_RATE)[0]\n",
    "            current_chunk.extend(data.flatten())  # Add the new data to the current chunk\n",
    "\n",
    "            # Check if the audio data is silent\n",
    "            if is_silent(data):\n",
    "                # If silence starts, begin a timer\n",
    "                if silence_start_time is None:\n",
    "                    silence_start_time = time.time()\n",
    "            else:\n",
    "                # Reset the timer if sound is detected\n",
    "                silence_start_time = None\n",
    "\n",
    "            # Stop recording if silence has lasted beyond the duration threshold\n",
    "            if silence_start_time and (time.time() - silence_start_time) > DURATION_THRESHOLD:\n",
    "                print(\"Silence detected. Stopping recording.\")\n",
    "                break  # Exit the loop to stop recording\n",
    "\n",
    "    # Save the final chunk after breaking out of the loop\n",
    "    if current_chunk:\n",
    "        save_audio_chunk(current_chunk)\n",
    "        print(\"Final chunk saved.\")\n",
    "\n",
    "def save_temp_wav(file_path, chunk):\n",
    "    \"\"\"Save the recorded audio chunk to a WAV file temporarily for further processing or conversion.\"\"\"\n",
    "    if len(chunk) == 0:\n",
    "        return  # Don't save empty chunks\n",
    "    \n",
    "    # Convert to WAV and save\n",
    "    audio_data = np.array(chunk, dtype=np.float32)\n",
    "    write(file_path, SAMPLE_RATE, audio_data)\n",
    "\n",
    "def convert_to_mp3(wav_file, mp3_file):\n",
    "    \"\"\"Convert a temporary WAV file to MP3 format using the Pydub library.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(wav_file)\n",
    "        audio = audio.set_channels(1)  # Ensure mono channel\n",
    "        audio = audio.set_frame_rate(16000)  # Set sample rate to 16 kHz (Whisper's recommended rate)\n",
    "        audio.export(mp3_file, format=\"mp3\", bitrate=\"128k\")  # Set bitrate to 128 kbps\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to MP3: {e}\")\n",
    "\n",
    "\n",
    "def save_audio_chunk(chunk):\n",
    "    \"\"\"Save the recorded audio chunk to an MP3 file, creating a unique file name.\"\"\"\n",
    "    if len(chunk) == 0:\n",
    "        return  # Don't save empty chunks\n",
    "\n",
    "    # Create a unique file name for the MP3 file\n",
    "    chunk_index = len(os.listdir(CHUNK_FOLDER)) + 1\n",
    "    mp3_file_path = os.path.join(CHUNK_FOLDER, f\"chunk{chunk_index}.mp3\")\n",
    "\n",
    "    # Convert the chunk to WAV temporarily for saving\n",
    "    temp_wav_path = os.path.join(CHUNK_FOLDER, \"temp.wav\")\n",
    "    save_temp_wav(temp_wav_path, chunk)\n",
    "\n",
    "    # Convert to MP3\n",
    "    convert_to_mp3(temp_wav_path, mp3_file_path)\n",
    "\n",
    "    print(f\"Saved chunk to {mp3_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    record_audio()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo ir al tienda para comprar manzanas y platanos. Yo fui al tienda para comprar manzanas y platanos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuration\n",
    "CHUNK_FOLDER = \"audio_chunks\"  # Directory where audio chunks are stored\n",
    "USE_NEWEST_FILE = True         # Set to True to use the newest file, False to specify a file\n",
    "SPECIFIED_FILE = \"\"            # Leave empty to use the newest file, or specify a filename like \"speech.mp3\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get the newest file from the directory\n",
    "def get_newest_file(directory):\n",
    "    \"\"\"Return the newest file in the specified directory.\"\"\"\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    if not files:\n",
    "        return None\n",
    "    files.sort(key=lambda f: os.path.getmtime(os.path.join(directory, f)), reverse=True)\n",
    "    return os.path.join(directory, files[0])\n",
    "\n",
    "# Determine which file to use\n",
    "file_path = None\n",
    "if USE_NEWEST_FILE:\n",
    "    file_path = get_newest_file(CHUNK_FOLDER)\n",
    "else:\n",
    "    file_path = SPECIFIED_FILE if SPECIFIED_FILE else None\n",
    "\n",
    "if file_path:\n",
    "    # Open the audio file\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        # Perform transcription using Whisper model\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "        )\n",
    "\n",
    "        # Print the transcription text\n",
    "        print(transcription.text)\n",
    "else:\n",
    "    print(\"No audio file found. Please check the directory or specify a file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#transcribe to text\n",
    "audio_file = open(\"/path/to/file/speech.mp3\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file, \n",
    "  response_format=\"text\"\n",
    ")\n",
    "print(transcription.text)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo ir al tienda para comprar manzanas y platanos. Yo FUI al tienda para comprar manzanas y platanos.\n"
     ]
    }
   ],
   "source": [
    "#call gpt to check for grammar errors in the transcription\n",
    "\n",
    "foundError = complete(f\"{myPrompt2}\\n\\n{myText}\")\n",
    "print(foundError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo ir al tienda para comprar manzanas y platanos.', 'Yo FUI al tienda para comprar manzanas y platanos.']\n"
     ]
    }
   ],
   "source": [
    "# Divide up the transcription into sentences so each error can be looked at separately\n",
    "import nltk\n",
    "#nltk.download('punkt_tab')  # Download the punkt tokenizer if you haven't already\n",
    "\n",
    "def split_paragraph_into_sentences(paragraph):\n",
    "    sentences = nltk.tokenize.sent_tokenize(paragraph)\n",
    "    return sentences\n",
    "\n",
    "# Example usage\n",
    "responseSentenceSplit = split_paragraph_into_sentences(foundError)\n",
    "print(responseSentenceSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think if we just said it this way to begin with then it will skip over all the logic that deals \n",
    "# withthe while loop and we can go straight to the user getting to talk right away \n",
    "# which would be very convenientand would reuse the code\n",
    "\n",
    "errorsLeft = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattj\\AppData\\Local\\Temp\\ipykernel_3080\\590219557.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "#convert errors into audio\n",
    "if gptResponse = \"No Errors.\":\n",
    "    errorsLeft = False\n",
    "else:\n",
    "    errorsLeft = True\n",
    "    filename1 = \"speech.mp3\"\n",
    "    speech_file_path = Path.cwd() / filename1\n",
    "    response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=foundError\n",
    "    )\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n",
    "while errorsLeft:   \n",
    "    \n",
    "    # play audio back\n",
    "    audio = AudioSegment.from_mp3(speech_file_path)\n",
    "    play_obj = sa.play_buffer(\n",
    "        audio.raw_data,\n",
    "        num_channels=audio.channels,\n",
    "        bytes_per_sample=audio.sample_width,\n",
    "        sample_rate=audio.frame_rate\n",
    "    )\n",
    "    play_obj.wait_done()  # Wait until playback is finished\n",
    "\n",
    "    # Record the user response\n",
    "    # transcribe\n",
    "    # Check if they got it right using a gpt call, if they did they change errorLeft\n",
    "    # also check against other cases (as described below)\n",
    "    errorsLeft = False\n",
    "\n",
    "#No more errors, continue conversation, play 'cuentame.mp3' \n",
    "audio = AudioSegment.from_mp3(Path.cwd() / \"cuentame.mp3\")\n",
    "    play_obj = sa.play_buffer(\n",
    "        audio.raw_data,\n",
    "        num_channels=audio.channels,\n",
    "        bytes_per_sample=audio.sample_width,\n",
    "        sample_rate=audio.frame_rate\n",
    "    )\n",
    "    play_obj.wait_done()  # Wait until playback is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nif the last words said were  \\nnevermind - just move one\\nrepite - auto replay everything that was just said and ignore \\nrepite (algo) figure out what exactly i want repeated and repeat that audio slowly (consider slowing down the playback)\\n\\nListen to audio\\nI respond normally - one by one, go through the things that were said to me and check if i said them correctly back. \\n    if yes, then move to the next item,\\n    if no, add that item back to the audio output\\n    if all yes, then continue conversation\\n    otherwise, concat audio again and play new audio\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' \n",
    "Listen to audio\n",
    "\n",
    "if the last words said were  \n",
    "nevermind - just move one. this is tough because i might just completely move on, so you need logic to notice this has happened and ignore checking against old errors\n",
    "repite - auto replay everything that was just said and ignore \n",
    "repite (algo) figure out what exactly i want repeated and repeat that audio slowly (consider slowing down the playback)\n",
    "\n",
    "otherwise confirm that i repeated back the correction properly. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed audio saved as ./audio_chunks/chunk2_trim.mp3\n"
     ]
    }
   ],
   "source": [
    "# Deletes dead air at the beginning and end of MP3 files\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import os\n",
    "\n",
    "def trim_silence(input_file, silence_thresh=-40, min_silence_len=300, buffer_ms=200):\n",
    "    \"\"\"\n",
    "    Trim dead air (silence) from the beginning and end of an MP3 file, leaving a small buffer, and save it with '_trim' appended to the filename.\n",
    "    \n",
    "    :param input_file: Path to the input MP3 file\n",
    "    :param silence_thresh: Silence threshold in dB (default is -40 dB)\n",
    "    :param min_silence_len: Minimum length of silence to consider (in milliseconds)\n",
    "    :param buffer_ms: Extra milliseconds to leave at the beginning and end of the trimmed audio (default is 100 ms)\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_mp3(input_file)\n",
    "    \n",
    "    # Detect non-silent portions of the audio\n",
    "    non_silent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    \n",
    "    if non_silent_ranges:\n",
    "        # Get the start and end of the non-silent range and add buffer\n",
    "        start_trim = max(0, non_silent_ranges[0][0] - buffer_ms)\n",
    "        end_trim = min(len(audio), non_silent_ranges[-1][1] + buffer_ms)\n",
    "        \n",
    "        # Trim the audio with the buffer\n",
    "        trimmed_audio = audio[start_trim:end_trim]\n",
    "        \n",
    "        # Create output filename by appending '_trim' before the file extension\n",
    "        base, ext = os.path.splitext(input_file)\n",
    "        output_file = f\"{base}_trim{ext}\"\n",
    "        \n",
    "        # Export the trimmed audio to an MP3 file\n",
    "        trimmed_audio.export(output_file, format=\"mp3\")\n",
    "        print(f\"Trimmed audio saved as {output_file}\")\n",
    "    else:\n",
    "        print(\"No non-silent segments detected. File not saved.\")\n",
    "\n",
    "# Example usage\n",
    "input_mp3 = \"./audio_chunks/chunk2.mp3\"\n",
    "trim_silence(input_mp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myText = \"Yo ir al tienda para comprar manzanas y platanos. Cuando llegué, vi muchas frutas y verduras. El cajero me dijo que el precio son muy alto, pero no me importa. Después, yo regresar a casa y preparé un plato grande para mi familia. Todos nos gusta comer juntos.\"\n",
    "#myText = \"Hola, como estas\"\n",
    "#Prompt1 is show all the errors in a list\n",
    "myPrompt1 = \"\"\"\n",
    "You will receive a paragraph written in Spanish. Your task is to identify and correct major grammatical errors while adhering to the following instructions:\n",
    "\n",
    "1. Ignore gender errors.\n",
    "2. If a mistake is made but then corrected within the same paragraph, do not include that correction (e.g., \"yo comí\" followed by \"yo comer\").\n",
    "3. Ignore typing mistakes or missing accents; these are not considered errors.\n",
    "4. Ignore minor clarity issues.\n",
    "5. If there are no errors worth mentioning, output \"No Errors.\"\n",
    "\n",
    "Your output should consist only of the correct Spanish for each identified error, separated by periods. Do not provide any additional commentary or explanations. Aim for responses of 4-5 words unless more is needed.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input: \"Nosotros va a la playa mañana. Ellos trae sus juguetes.\"\n",
    "\n",
    "Output: \"Nosotros vamos. Ellos traen.\"\n",
    "\"\"\"\n",
    " #prompt2 find one error and give the complete correction\n",
    "myPrompt2 = \"\"\" \n",
    "You will receive a paragraph written in Spanish. Your task is to identify and correct one major grammatical error while adhering to the following instructions:\n",
    "Ignore gender errors.\n",
    "If a mistake is made but then corrected within the same paragraph, do not include that correction (e.g., \"yo comí\" followed by \"yo comer\").\n",
    "Ignore typing mistakes or missing accents; these are not considered errors.\n",
    "Ignore minor clarity issues.\n",
    "If there are no significant errors, output \"No Errors.\"\n",
    "Your output should consist of three sentences:\n",
    "\n",
    "The original incorrect sentence, abreviated to show what was said, but not include extraneous detail before and after in the sentence.\n",
    "The corrected version with the corrected word in all caps.\n",
    "If no significant error is found, just write \"No Errors.\"\n",
    "Example:\n",
    "\n",
    "Input: Ayer, nosotros va a la playa mañana para solear. Ellos trae sus juguetes.\n",
    "\n",
    "Output: Nosotros va a la playa mañana. Nosotros VAMOS a la playa mañana.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
